import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import json
import backend_client

st.set_page_config(
    page_title="RAGè¯„ä¼°ç»“æœå¯¹æ¯”",
    page_icon="ğŸ“Š",
    layout="wide"
)

def main():
    st.title("ğŸ“Š RAGè¯„ä¼°ç»“æœå¯¹æ¯”")
    
    # Check backend connection
    if not backend_client.test_connection():
        st.error("âŒ æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡ã€‚è¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œã€‚")
        st.stop()
    
    # Sidebar navigation
    page = st.sidebar.selectbox(
        "é€‰æ‹©é¡µé¢",
        ["è¯„ä¼°å†å²", "ç»“æœå¯¹æ¯”", "æ–°å»ºè¯„ä¼°"]
    )
    
    if page == "è¯„ä¼°å†å²":
        show_evaluation_history()
    elif page == "ç»“æœå¯¹æ¯”":
        show_comparison_page()
    elif page == "æ–°å»ºè¯„ä¼°":
        show_new_evaluation()

def show_evaluation_history():
    st.header("ğŸ“‹ è¯„ä¼°å†å²")
    
    # Get evaluation history
    history_response = backend_client.get_evaluation_history()
    if not history_response:
        st.warning("æ— æ³•è·å–è¯„ä¼°å†å²")
        return
    
    history = history_response.get('history', [])
    if not history:
        st.info("æš‚æ— è¯„ä¼°å†å²è®°å½•")
        return
    
    # Convert to DataFrame for display
    df_history = pd.DataFrame(history)
    df_history['timestamp'] = pd.to_datetime(df_history['timestamp']).dt.strftime('%Y-%m-%d %H:%M')
    
    # Display history table
    st.subheader(f"å…± {len(history)} æ¡è®°å½•")
    
    for i, record in enumerate(history):
        with st.expander(f"ğŸ“Š {record['name']} - {record['timestamp'][:16]}"):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.write(f"**LLMæä¾›å•†**: {record['llm_provider']}")
                if record.get('model_name'):
                    st.write(f"**æ¨¡å‹**: {record['model_name']}")
                
                # Dataset info
                dataset_info = record.get('dataset_info', {})
                st.write(f"**æ•°æ®é›†å¤§å°**: {dataset_info.get('size', 'N/A')}")
                
                # Results summary
                results = record.get('results_summary', {})
                if 'final_score' in results:
                    st.write(f"**æ€»ä½“å¾—åˆ†**: {results['final_score']:.3f}")
                
                sample_count = results.get('sample_count', record.get('dataset_info', {}).get('size', 'N/A'))
                st.write(f"**æ ·æœ¬æ•°é‡**: {sample_count}")
                
                # Notes
                if record.get('notes'):
                    st.write(f"**å¤‡æ³¨**: {record['notes']}")
            
            with col2:
                # Edit notes
                new_notes = st.text_area(
                    "ç¼–è¾‘å¤‡æ³¨",
                    value=record.get('notes', ''),
                    key=f"notes_{record['id']}"
                )
                
                if st.button("ä¿å­˜å¤‡æ³¨", key=f"save_{record['id']}"):
                    result = backend_client.update_evaluation_notes(record['id'], new_notes)
                    if result:
                        st.success("å¤‡æ³¨å·²æ›´æ–°")
                        st.rerun()
                    else:
                        st.error("æ›´æ–°å¤±è´¥")
                
                if st.button("åˆ é™¤", key=f"delete_{record['id']}", type="secondary"):
                    result = backend_client.delete_evaluation(record['id'])
                    if result:
                        st.success("è®°å½•å·²åˆ é™¤")
                        st.rerun()
                    else:
                        st.error("åˆ é™¤å¤±è´¥")

def show_comparison_page():
    st.header("ğŸ” ç»“æœå¯¹æ¯”")
    
    # Get evaluation history
    history_response = backend_client.get_evaluation_history()
    if not history_response:
        st.warning("æ— æ³•è·å–è¯„ä¼°å†å²")
        return
    
    history = history_response.get('history', [])
    if len(history) < 2:
        st.info("è‡³å°‘éœ€è¦2æ¡è¯„ä¼°è®°å½•æ‰èƒ½è¿›è¡Œå¯¹æ¯”")
        return
    
    # Selection for comparison
    st.subheader("é€‰æ‹©è¦å¯¹æ¯”çš„è¯„ä¼°ç»“æœ")
    
    evaluation_options = {
        f"{record['name']} ({record['timestamp'][:16]})": record['id'] 
        for record in history
    }
    
    selected_evaluations = st.multiselect(
        "é€‰æ‹©è¯„ä¼°ç»“æœï¼ˆè‡³å°‘é€‰æ‹©2ä¸ªï¼‰",
        options=list(evaluation_options.keys()),
        default=list(evaluation_options.keys())[:2] if len(evaluation_options) >= 2 else []
    )
    
    if len(selected_evaluations) < 2:
        st.warning("è¯·è‡³å°‘é€‰æ‹©2ä¸ªè¯„ä¼°ç»“æœè¿›è¡Œå¯¹æ¯”")
        return
    
    selected_ids = [evaluation_options[name] for name in selected_evaluations]
    
    if st.button("å¼€å§‹å¯¹æ¯”"):
        comparison_result = backend_client.compare_evaluations(selected_ids)
        if comparison_result:
            show_comparison_results(comparison_result)
        else:
            st.error("å¯¹æ¯”å¤±è´¥")

def show_comparison_results(comparison_result):
    st.subheader("ğŸ“ˆ å¯¹æ¯”ç»“æœ")
    
    evaluations = comparison_result['evaluations']
    
    # Extract metrics for comparison
    metrics_data = []
    for eval_data in evaluations:
        results = eval_data['results_summary']
        row = {
            'name': eval_data['name'],
            'timestamp': eval_data['timestamp'][:16],
            'llm_provider': eval_data['llm_provider'],
            'overall_score': results.get('final_score', 0),
            'sample_count': results.get('sample_count', 0)
        }
        
        # Add individual metric scores
        for metric in results.get('metrics', []):
            row[metric['name']] = metric['score']
        
        metrics_data.append(row)
    
    df_comparison = pd.DataFrame(metrics_data)
    
    # Display comparison table
    st.subheader("ğŸ“‹ è¯¦ç»†å¯¹æ¯”è¡¨")
    st.dataframe(df_comparison, use_container_width=True)
    
    # Visualizations
    st.subheader("ğŸ“Š å¯è§†åŒ–å¯¹æ¯”")
    
    # Overall score comparison
    fig_overall = px.bar(
        df_comparison,
        x='name',
        y='overall_score',
        title='æ€»ä½“å¾—åˆ†å¯¹æ¯”',
        color='name'
    )
    st.plotly_chart(fig_overall, use_container_width=True)
    
    # Individual metrics comparison (radar chart)
    metric_columns = [col for col in df_comparison.columns 
                     if col not in ['name', 'timestamp', 'llm_provider', 'overall_score']]
    
    if metric_columns:
        st.subheader("ğŸ¯ å„é¡¹æŒ‡æ ‡å¯¹æ¯”ï¼ˆé›·è¾¾å›¾ï¼‰")
        
        fig_radar = go.Figure()
        
        for _, row in df_comparison.iterrows():
            values = [row[metric] for metric in metric_columns]
            values.append(values[0])  # Close the radar chart
            
            fig_radar.add_trace(go.Scatterpolar(
                r=values,
                theta=metric_columns + [metric_columns[0]],
                fill='toself',
                name=row['name']
            ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 1]
                )),
            showlegend=True,
            title="å„é¡¹æŒ‡æ ‡å¯¹æ¯”"
        )
        
        st.plotly_chart(fig_radar, use_container_width=True)
    
    # Download comparison results
    st.subheader("ğŸ“¥ å¯¼å‡ºå¯¹æ¯”ç»“æœ")
    
    csv_data = df_comparison.to_csv(index=False)
    st.download_button(
        label="ä¸‹è½½CSVæ ¼å¼",
        data=csv_data,
        file_name=f"evaluation_comparison_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
        mime="text/csv"
    )
    
    json_data = json.dumps(comparison_result, indent=2, ensure_ascii=False)
    st.download_button(
        label="ä¸‹è½½JSONæ ¼å¼",
        data=json_data,
        file_name=f"evaluation_comparison_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
        mime="application/json"
    )

def show_new_evaluation():
    st.header("ğŸ†• æ–°å»ºè¯„ä¼°")
    st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è·³è½¬åˆ°è¯„ä¼°é¡µé¢")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("æ ‡å‡†è¯„ä¼°æµç¨‹", type="primary"):
            st.switch_page("app.py")
    
    with col2:
        if st.button("ä¸¤æ­¥å¼å·¥ä½œæµ", type="secondary"):
            st.switch_page("app_two_step.py")

if __name__ == "__main__":
    main() 