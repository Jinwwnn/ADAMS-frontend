# ğŸ“Š RAG Evaluation Results Comparison

## ğŸ¯ Overview

The evaluation comparison feature allows users to save, view, and compare multiple evaluation results across different datasets, models, and configurations.

## ğŸš€ Features

### âœ… **Evaluation History Management**
- **Automatic Saving**: Save evaluation results with custom names and notes
- **Lightweight Storage**: Only metadata and summaries stored (not full datasets)
- **Easy Management**: Edit notes, delete records, view history
- **JSON Storage**: Simple file-based storage (`backend/evaluation_history.json`)

### âœ… **Results Comparison**
- **Multi-Evaluation Comparison**: Compare 2+ evaluation results simultaneously
- **Visual Comparisons**: Bar charts for overall scores, radar charts for individual metrics
- **Detailed Tables**: Side-by-side metric comparison
- **Export Options**: Download comparison results in CSV/JSON formats

### âœ… **Three Application Interfaces**
1. **Standard Evaluation** (`app.py`): Main evaluation workflow with save functionality
2. **Two-Step Workflow** (`app_two_step.py`): Data augmentation + evaluation with independent Step 2
3. **Comparison Dashboard** (`app_comparison.py`): Dedicated comparison and history management

## ğŸ“ File Structure

```
frontend/
â”œâ”€â”€ app.py                    # Main evaluation app (with save feature)
â”œâ”€â”€ app_two_step.py          # Two-step workflow (English version)
â”œâ”€â”€ app_comparison.py        # Comparison dashboard (English version)
â””â”€â”€ backend_client.py        # API client with history management methods

backend/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ models.py            # EvaluationHistory, SaveEvaluationRequest models
â”‚   â”œâ”€â”€ evaluation_service.py # History management service methods
â”‚   â””â”€â”€ app.py               # API endpoints for history management
â””â”€â”€ evaluation_history.json  # JSON storage file (auto-created)

startup scripts/
â”œâ”€â”€ start_comparison_app.py           # Launch comparison app (port 8502)
â””â”€â”€ start_frontend_comparison_poetry.py # Poetry version
```

## ğŸ”§ API Endpoints

- `POST /evaluation/save` - Save evaluation result
- `GET /evaluation/history` - Get all evaluation history
- `GET /evaluation/history/{id}` - Get specific evaluation
- `DELETE /evaluation/history/{id}` - Delete evaluation
- `PUT /evaluation/history/{id}/notes` - Update notes
- `POST /evaluation/compare` - Compare multiple evaluations

## ğŸ’¾ Storage Details

### What's Stored:
- âœ… Evaluation metadata (name, timestamp, LLM provider, model)
- âœ… Dataset information (size, columns, upload time)
- âœ… Metric scores and final scores
- âœ… Configuration (selected evaluators, weights)
- âœ… User notes

### What's NOT Stored:
- âŒ Full original datasets
- âŒ Complete processed results
- âŒ Large intermediate files

**Storage Size**: ~1-2KB per evaluation record

## ğŸš€ Usage Guide

### 1. Running the Applications

```bash
# Standard evaluation (port 8501)
python start_frontend_poetry.py

# Two-step workflow (port 8501)  
python start_frontend_two_step.py

# Comparison dashboard (port 8502)
python start_comparison_app.py
```

### 2. Saving Evaluation Results

1. Complete an evaluation in `app.py` or `app_two_step.py`
2. Scroll to "Save Evaluation Results" section
3. Enter a name and optional notes
4. Click "Save Evaluation Result"
5. Record is automatically saved to history

### 3. Viewing and Comparing Results

1. Open comparison dashboard: `http://localhost:8502`
2. **Evaluation History Tab**: View all saved evaluations
3. **Results Comparison Tab**: Select 2+ evaluations to compare
4. **Visual Comparisons**: Automatic charts and tables
5. **Export**: Download comparison results

## ğŸ”„ Integration Status

### âœ… **Fully Integrated Components**

1. **Backend Storage Service** âœ…
   - History management methods in `evaluation_service.py`
   - API endpoints in `app.py`
   - Lightweight storage model

2. **Frontend Applications** âœ…
   - Save functionality in main evaluation app
   - Independent Step 2 in two-step workflow
   - Dedicated comparison dashboard

3. **All Text Localized** âœ…
   - All Chinese text replaced with English
   - Consistent UI language across applications
   - English comments and documentation

4. **Client-Server Communication** âœ…
   - HTTP API methods in `backend_client.py`
   - Error handling and offline fallbacks
   - Real-time progress tracking

## ğŸ¯ Key Benefits

- **Zero Database Setup**: Simple JSON file storage
- **Lightweight**: Only essential data stored
- **Fast Comparisons**: Instant visual comparisons
- **Flexible**: Works with any evaluation configuration
- **User-Friendly**: Intuitive interface for history management
- **Export Ready**: Multiple download formats

## ğŸ”§ Technical Features

- **Dynamic Metric Pool**: Automatically detects available evaluators
- **Real-time Updates**: Live progress tracking and updates
- **Graceful Fallbacks**: Works offline with simulated data
- **Concurrent Safe**: Thread-safe file operations
- **UTF-8 Support**: Full international character support

The evaluation comparison system is now **fully integrated and ready for production use**! ğŸ‰ 